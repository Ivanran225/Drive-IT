{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goals for this Advanced Lane Finding Project project are:\n",
    "\n",
    "### -- Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "### -- Apply a distortion correction to raw images.\n",
    "### -- Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "### -- Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "### -- Detect lane pixels and fit to find the lane boundary.\n",
    "### -- Determine the curvature of the lane and vehicle position with respect to center.\n",
    "### -- Warp the detected lane boundaries back onto the original image.\n",
    "### -- Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for the Advanced Lane Finding project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import glob\n",
    "from tracker import tracker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I prepared the \"object points\", which are the three dimensions of the chessboard corners in the real world. The object points are reshaped to create \"image points\" which are two dimensional coordinates in the image plane. OpenCV functions findChessboardCorners() and drawChessboardCorners() were used to automatically find and draw corners in an image of a chessboard pattern.\n",
    "\n",
    "### I then used the output objpoints and imgpoints to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function. I applied this distortion correction to the test image using the cv2.undistort() function and obtained this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Calibrate the Camera\n",
    "# number of inside corners in x & y directions\n",
    "nx = 9 \n",
    "ny = 6\n",
    "# prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(5,4)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.05, hspace=0.15)  \n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, add to object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name,img)\n",
    "        img_plt = plt.subplot(grid[idx])\n",
    "        plt.axis('on')\n",
    "        img_plt.set_xticklabels([])\n",
    "        img_plt.set_yticklabels([])\n",
    "        #img_plt.set_aspect('equal')\n",
    "        plt.imshow(img)\n",
    "        plt.title(write_name)\n",
    "        plt.axis('off')\n",
    "plt.show()\n",
    "    #plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It should be noted that some of the images are not plotted above because the \"findChessboardCorners()\" function could not find 9 x 6 inside corners inside these input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the objpoints and imgpoints to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function. This distortion correction was applied to the test image using the cv2.undistort() function. The results are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Take an image, object points, image points, and perform the camera calibration. Undistort the image after camera calibration\n",
    "        \n",
    "#load image for reference\n",
    "image = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "img_size = (image.shape[1],image.shape[0])\n",
    "\n",
    "# Perform camera calibration with the given object and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "# Save the camera calibration results for later use\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"./camera_cal/calibration_pickle.p\", \"wb\"))\n",
    "\n",
    "#Visualize the before/after distortion on chessboard images\n",
    "undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "img_plt = plt.subplot(grid[0])\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "\n",
    "img_plt = plt.subplot(grid[1])\n",
    "plt.imshow(undist)\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Choose from the test images to demonstrate the before/after applying undistortion \n",
    "testImg = cv2.imread('./test_images/test5.jpg')\n",
    "testImg = cv2.cvtColor(testImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "undistTest = cv2.undistort(testImg, mtx, dist, None, mtx)\n",
    "\n",
    "#Visualize the before/after distortion on test images\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "img_plt = plt.subplot(grid[0])\n",
    "plt.imshow(testImg)\n",
    "plt.title('Original test Image')\n",
    "\n",
    "img_plt = plt.subplot(grid[1])\n",
    "plt.imshow(undistTest)\n",
    "plt.title('Undistorted test Image')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although it may not be visible at a first glance, a closer look at the sides of the undistorted image above shows that the radial distortion has been removed. An example where this is obvious: the white car on the right is slightly cropped along with the trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions are defined for experimenting with different color thresholds and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Define a function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(l_channel, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(l_channel, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to return the magnitude of the gradient for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def color_threshold(image, sthresh=(0,255), vthresh=(0,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel > sthresh[0]) & (s_channel <= sthresh[1])] = 1\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel > vthresh[0]) & (v_channel <= vthresh[1])] = 1\n",
    "\n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_binary == 1) & (v_binary) == 1] = 1\n",
    "\n",
    "    # Return the combined s_channel & v_channel binary image\n",
    "    return output\n",
    "\n",
    "def s_channel_threshold(image, sthresh=(0,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:, :, 2]  # use S channel\n",
    "\n",
    "    # create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= sthresh[0]) & (s_channel <= sthresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height), max(0,int(center-width)):min(int(center+width),img_ref.shape[1])] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Apply Sobel operator in X-direction to experiment with gradient thresholds\n",
    "gradx = abs_sobel_thresh(undistTest, orient='x', thresh_min=20, thresh_max=100)\n",
    "\n",
    "#Visualize the results before/after absolute sobel operator is applied on a test image in x direction to find the\n",
    "#vertical lines, since the lane lines are close to being vertical\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(gradx, cmap=\"gray\")\n",
    "plt.title('Absolute sobel threshold in X direction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Apply Sobel operator in Y-direction to experiment with gradient thresholds\n",
    "grady = abs_sobel_thresh(undistTest, orient='y', thresh_min=20, thresh_max=100)\n",
    "\n",
    "#Visualize the results before/after sobel operator is applied on a test image in y direction \n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(grady, cmap=\"gray\")\n",
    "plt.title('Absolute sobel threshold in Y direction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Apply magnitude threshold\n",
    "magThr = mag_thresh(undistTest, sobel_kernel=3, mag_thresh=(30, 100))\n",
    "\n",
    "#Visualize the results before/after applying magnitude thresholds\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(magThr, cmap=\"gray\")\n",
    "plt.title('After applying Magnitude Threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dirThr = dir_threshold(undistTest, sobel_kernel=31, thresh=(0.5, 1))\n",
    "\n",
    "#Visualize the results before/after direction threshold is applied\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(dirThr, cmap=\"gray\")\n",
    "plt.title('After applying direction Threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#use s channel alone in HLS colorspace and experiment with thresholds\n",
    "s_binary = s_channel_threshold(undistTest, sthresh=(170,255))\n",
    "\n",
    "#Visualize the results before/after s channel threshold is applied\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(s_binary, cmap=\"gray\")\n",
    "plt.title('After applying S-channel Threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Experiment with HLS & HSV color spaces along with thresholds\n",
    "c_binary = color_threshold(undistTest, sthresh=(100,255), vthresh=(50,255))\n",
    "\n",
    "#Visualize the results before/after HLS/HSV  threshold is applied\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(c_binary, cmap=\"gray\")\n",
    "plt.title('After applying color threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After experimenting with several thresholds and color spaces, I chose to use the combined binary thresholded image from the Sobel threshold in the x & y directions along with the color thresholds in the H & V channels, to get clear lane lines in all the test images. This forms the image processing pipeline for generating a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Combine the binary images using the Sobel thresholds in X/Y directions along with the color threshold to form the final image pipeline\n",
    "preprocessImage = np.zeros_like(undistTest[:,:,0])\n",
    "preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "#Visualize the results before/after combining the images from the pipeline\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(preprocessImage, cmap=\"gray\")\n",
    "plt.title('After image processing pipeline')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the test images, pass them through the pipeline, warp the perspective by selecting a region of interest within the image, and create a bird's eye view. Visualize the results and ensure that the selected region of interest is appropriate by confirming that the lane lanes are indeed parallel to each other after warping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Read and make a list of test images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "gidx = 0\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    #pass image thru the pipeline\n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "\n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "\n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])\n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #Visualize the results before/after warping for a birds-eye view along with the source & destination co-ordinate locations\n",
    "    plt.figure(figsize = (30,20))\n",
    "    grid = gridspec.GridSpec(8,2)\n",
    "    # set the spacing between axes.\n",
    "    grid.update(wspace=0.05, hspace=0.05)  \n",
    "\n",
    "    plt.subplot(grid[gidx])\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    for i in range(4):\n",
    "        plt.plot(src[i][0],src[i][1],'rs')\n",
    "    plt.title('Undistorted Image')\n",
    "\n",
    "    plt.subplot(grid[gidx+1])\n",
    "    plt.imshow(warped, cmap=\"gray\")\n",
    "    for i in range(4):\n",
    "        plt.plot(dst[i][0],dst[i][1],'rs')\n",
    "    plt.title('Birds eye view')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply convolution which will maximize the number of \"hot\" pixels in each window. This convolution is the summation of the product of two separate signals: the window template and the vertical slice of the pixel image. The window template is slid across the image from left to right and any overlapping values are summed together, creating the convolved signal. The peak of the convolved signal is where the highest overlap of pixels occured and is the position for the lane marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    #pass image thru the pipeline\n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])\n",
    "   \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 50\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "\n",
    "    #Visualize the results of the window fitting to lane lines\n",
    "    plt.imshow(result, cmap='gray')\n",
    "    plt.title('Window fitting results')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a polynomial to the identified lane lines on the left and the right. Visualize the results by overlapping the lane lines on to the original undistorted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "gidx=0\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    #pass image thru the pipeline\n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])   \n",
    "    \n",
    "    #src = np.float32([(532, 496), (756, 496), (288, 664), (1016, 664)])\n",
    "    #dst = np.float32([(src[2][0], src[2][1] - 200),(src[3][0], src[3][1] - 200),(src[2][0], src[2][1]),(src[3][0], src[3][1])])\n",
    "\n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 50\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "    \n",
    "    #fit the lane boundaries to the left, right center positions found\n",
    "    yvals = range(0,warped.shape[0])\n",
    "    \n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx,np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx,np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2, left_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "\n",
    "    road = np.zeros_like(img)\n",
    "    road_bkg = np.zeros_like(img)\n",
    "    cv2.fillPoly(road,[left_lane],color=[255,0,0])\n",
    "    cv2.fillPoly(road,[right_lane],color=[0,0,255])\n",
    "    cv2.fillPoly(road_bkg,[left_lane],color=[255,255,255])\n",
    "    cv2.fillPoly(road_bkg,[right_lane],color=[255,255,255])\n",
    "\n",
    "    road_warped = cv2.warpPerspective(road,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg= cv2.warpPerspective(road_bkg,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img,1.0,road_warped, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base,1.0,road_warped, 1.0, 0.0)\n",
    "\n",
    "    #Visualize the results of identified lane lines and overlapping them on to the original undistorted image\n",
    "    plt.figure(figsize = (30,20))\n",
    "    grid = gridspec.GridSpec(8,2)\n",
    "    # set the spacing between axes.\n",
    "    grid.update(wspace=0.05, hspace=0.05)  \n",
    "\n",
    "    #img_plt = plt.subplot(grid[0])\n",
    "    plt.subplot(grid[gidx])\n",
    "    plt.imshow(road, cmap=\"gray\")\n",
    "    plt.title('Identified lane lines')\n",
    "\n",
    "    #img_plt = plt.subplot(grid[1])\n",
    "    plt.subplot(grid[gidx+1])\n",
    "    plt.imshow(result, cmap=\"gray\")\n",
    "    plt.title('Lane lines overlapped on original image')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the radius of curvature using polynomial fit functions, and the position of the camera/car's center from the left or right lane. Display these results along with the fitted lane lines on top of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "gidx=0\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])   \n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 25\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "    \n",
    "    #fit the lane boundaries to the left, right center positions found\n",
    "    yvals = range(0,warped.shape[0])\n",
    "    \n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx,np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx,np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2, left_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    middle_marker = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "\n",
    "    road = np.zeros_like(img)\n",
    "    road_bkg = np.zeros_like(img)\n",
    "    cv2.fillPoly(road,[left_lane],color=[255,0,0])\n",
    "    cv2.fillPoly(road,[right_lane],color=[0,0,255])\n",
    "    cv2.fillPoly(road_bkg,[left_lane],color=[255,255,255])\n",
    "    cv2.fillPoly(road_bkg,[right_lane],color=[255,255,255])\n",
    "\n",
    "    road_warped = cv2.warpPerspective(road,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg= cv2.warpPerspective(road_bkg,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img,1.0,road_warped, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base,1.0,road_warped, 1.0, 0.0)\n",
    "    ym_per_pix = curve_centers.ym_per_pix # meters per pixel in y dimension\n",
    "    xm_per_pix = curve_centers.xm_per_pix # meters per pixel in x dimension\n",
    "\n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals,np.float32)*ym_per_pix,np.array(leftx,np.float32)*xm_per_pix,2)\n",
    "    curverad = ((1 + (2*curve_fit_cr[0]*yvals[-1]*ym_per_pix + curve_fit_cr[1])**2)**1.5) /np.absolute(2*curve_fit_cr[0])\n",
    "    \n",
    "    # Calculate the offset of the car on the road\n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    center_diff = (camera_center-warped.shape[1]/2)*xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "\n",
    "    # draw the text showing curvature, offset & speed\n",
    "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "\n",
    "    plt.imshow(result, cmap='gray')\n",
    "    plt.title('Final image results')\n",
    "    plt.show()\n",
    "    \n",
    "    write_name='./test_images/tracked'+str(idx)+'.jpg'\n",
    "    cv2.imwrite(write_name, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process videos to display the fitted lane lines, radius of curvature, and position of the car from the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Set up the process videos function\n",
    "def process_image(img):\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    warptrap = np.copy(img)\n",
    "    cv2.line(warptrap, (int(src[0][0]), int(src[0][1])), (int(src[1][0]), int(src[1][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[1][0]), int(src[1][1])), (int(src[2][0]), int(src[2][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[2][0]), int(src[2][1])), (int(src[3][0]), int(src[3][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[3][0]), int(src[3][1])), (int(src[0][0]), int(src[0][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    \n",
    "    #pass image thru the pipeline\n",
    "    #preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    #gradx = abs_sobel_thresh(img, orient='x',thresh_min=20, thresh_max=100)\n",
    "    #s_binary = s_channel_threshold(img, sthresh=(170,255))\n",
    "    #preprocessImage[((gradx == 1) | (s_binary == 1))] = 1\n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    binaryImage = np.copy(preprocessImage)\n",
    "    binaryImage = np.array(cv2.merge((binaryImage,binaryImage,binaryImage)),np.uint8)\n",
    "    cv2.putText(binaryImage, 'Binary Image',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])   \n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 25\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "\n",
    "    windowfit = np.copy(result)\n",
    "    cv2.putText(windowfit, 'Sliding window results',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    warpage1 = np.copy(warpage)\n",
    "    cv2.putText(warpage1, 'Bird\\'s-eye View',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.line(warpage1, (int(dst[0][0]), int(dst[0][1])), (int(dst[1][0]), int(dst[1][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[1][0]), int(dst[1][1])), (int(dst[2][0]), int(dst[2][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[2][0]), int(dst[2][1])), (int(dst[3][0]), int(dst[3][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[3][0]), int(dst[3][1])), (int(dst[0][0]), int(dst[0][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    \n",
    "    #fit the lane boundaries to the left, right center positions found\n",
    "    yvals = range(0,warped.shape[0])\n",
    "    \n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx,np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx,np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2, left_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    middle_marker = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    inner_lane = np.array(list(zip(np.concatenate((left_fitx+window_width/2, right_fitx[::-1]-window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "\n",
    "    road = np.zeros_like(img)\n",
    "    road_bkg = np.zeros_like(img)\n",
    "    cv2.fillPoly(road,[left_lane],color=[255,0,0])\n",
    "    cv2.fillPoly(road,[right_lane],color=[0,0,255])\n",
    "    cv2.fillPoly(road,[inner_lane],color=[0,255,0])\n",
    "    cv2.fillPoly(road_bkg,[left_lane],color=[255,255,255])\n",
    "    cv2.fillPoly(road_bkg,[right_lane],color=[255,255,255])\n",
    "    \n",
    "    #Results screen portion for polynomial fit\n",
    "    road1 = np.copy(road)\n",
    "    cv2.putText(road1, 'Polynomial fit',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    road_warped = cv2.warpPerspective(road,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg= cv2.warpPerspective(road_bkg,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img,1.0,road_warped, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base,1.0,road_warped, 1.0, 0.0)\n",
    "    ym_per_pix = curve_centers.ym_per_pix # meters per pixel in y dimension\n",
    "    xm_per_pix = curve_centers.xm_per_pix # meters per pixel in x dimension\n",
    "\n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals,np.float32)*ym_per_pix,np.array(leftx,np.float32)*xm_per_pix,2)\n",
    "    curverad = ((1 + (2*curve_fit_cr[0]*yvals[-1]*ym_per_pix + curve_fit_cr[1])**2)**1.5) /np.absolute(2*curve_fit_cr[0])\n",
    "    \n",
    "    # Calculate the offset of the car on the road\n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    center_diff = (camera_center-warped.shape[1]/2)*xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "\n",
    "    # draw the text showing curvature, offset & speed\n",
    "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "\n",
    "    height, width = 1080, 1920\n",
    "    FinalScreen = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    FinalScreen[0:720,0:1280] = cv2.resize(result, (1280,720), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[0:360,1280:1920] = cv2.resize(warptrap, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[360:720,1280:1920] = cv2.resize(binaryImage, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,1280:1920] = cv2.resize(warpage1, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,0:640] = cv2.resize(windowfit, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[720:1080,640:1280] = cv2.resize(road1, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    return FinalScreen\n",
    "\n",
    "Output_video = 'output1_tracked.mp4'\n",
    "Input_video = 'project_video.mp4'\n",
    "#Output_video = 'output_challenge_video.mp4'\n",
    "#Input_video = 'harder_challenge_video.mp4'\n",
    "#Output_video = 'output_challenge_video.mp4'\n",
    "#Input_video = 'challenge_video.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(Input_video)\n",
    "video_clip = clip1.fl_image(process_image) # This function expects color images\n",
    "video_clip.write_videofile(Output_video, audio=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: The above solution works well on the standard video. However, it needs to be improved for the challenge videos. This is because the lanes are different in the challenge video: half of the lane is a freshly paved road and is different in color with the other other half of the lane. Also, the harder challenge video has glare on the camera as a result of direct sunlight falling on it, as well as high contrast contributing to washed out lane lines. This creates problems for the algorithm. One solution would be to dynamically adjust the contrast of the image frames dynamically to ensure images are not washed out and make sure they have a good dynamic range to work with in all lighting conditions. The harder challenge videos also have roads which are curvy and have a slope which makes it difficult to warp the images properly to feed into the algorithm. This can also be addressed by creating a dynamic region of interest for each image frame. These are some of the things that need to be explored when time permits. Overall, there is a lot of trail and error process in this project which makes it quite time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLa ejecución de celdas con 'Python 3.10.0 64-bit (system)' requieren el paquete ipykernel.\n",
      "Ejecute el siguiente comando para instalar 'ipykernel' en el entorno de Python. comando \r\n",
      ": 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
